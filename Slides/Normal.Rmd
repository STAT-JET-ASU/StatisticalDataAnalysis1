---
title: "Normal (Gaussian) Distribution"
author: "Author: Jill E. Thomley"
date: 'Updated: `r format(Sys.time(), "%A, %B %d, %Y @ %X")`'
output: ioslides_presentation
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(comment="", message=FALSE, warning=FALSE)
library(ggplot2)
library(dplyr)
```


# Normal Distribution

## The Normal Model

The normal distribution is a continuous probability distribution. Very few concepts in real life are truly normally distributed, but many are _approximately_ normal. The normal is also the limiting distribution for many common statistics and other distributions when sample size n $\rightarrow \infty$.

$$X \sim N(\mu,\sigma^2)$$

sample space _x_ = {-$\infty$ to +$\infty$}
    
$\mu$ = the mean of the distribution
    
$\sigma^2$ = the variance of the distribution

The standard normal distribution $Z$ has $\mu$ = 0 and $\sigma^2$ = $\sigma$ = 1.


## Probability Density Function (pdf)

Unlike the pmf in discrete distributions, the probability density function (pdf) of a continuous distribution does not compute probability, because the area under a point is zero. Instead it gives the height of the function (y) at x.

$$f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-(x-\mu)^2/(2\sigma^2)}$$

R has a function to solve the pmf for any given normal model. Inputs may be single values or vectors.

<center>$f(x)$ = `dnorm(x, mu, sigma)`</center><br>

Note that the function uses $\sigma$ rather than $\sigma^2$ as the parameter. 


## Standard Normal Density

```{r, fig.height=3.25}
ggplot(NULL, aes(-4:4)) + 
  stat_function(fun = dnorm, args = list(0, 1)) +
  scale_x_continuous(breaks = seq(-4, 4, 1)) +
  labs(x = "x", y = "f(x)")
```


## Cumulative Distribution Function (CDF)

The probability of a given number of successes _or fewer_ is found using the CDF, which integrates the area under the curve. This is similar to a discrete distribution. The normal has no closed-form solution for $F(x)$. R has a function for the normal CDF / inverse.

$$F(x)=P(X \leq x) = \int\limits_{-\infty}^{+\infty} \frac{1}{\sqrt{2\pi}\sigma}e^{-(x-\mu)^2/(2\sigma^2)}dx$$

$P(X \leq x)$ = $F(x)$ = `pnorm(x, mu, sigma)`

$P(X > x)$ = $1-F(x)$ = `pnorm` with `lower.tail = FALSE`

$q^{th}$ percentile (approx) = $F^{-1}(x)$ = `qnorm(q, mu, sigma)` 


## Standard Normal CDF

```{r, fig.height=3.25}
ggplot(NULL, aes(-4:4)) + 
  stat_function(fun = pnorm, args = list(0, 1)) +
  scale_x_continuous(breaks = seq(-4, 4, 1)) +
  labs(x = "x", y = "f(x)")
```


## Expected Value and Variance

The expected (mean) number of successes and the variance of number of successes are found as follows. The expressions for expected value and variance simplify to parameters $\mu$ and $\sigma^2$.

$$E[X] = \int\limits_{-\infty}^{+\infty} x f(x) \rightarrow \mu$$

$$Var[X] = \int\limits_{-\infty}^{+\infty} (x - \mu)^2 f(x) \rightarrow \sigma^2$$

$$SD[X] = \sqrt{Var[X]}$$


## The Empirical Rule

The normal distribution is unimodal and perfectly symmetric.

<p style="text-align: center;"><img src="https://stat-jet-asu.github.io/Moodlepics/normaldist.jpg"></p>


* approximately 68% of the curve area is between $\mu \pm 1\sigma$ 
* approximately 95% of the curve area is between $\mu \pm 2\sigma$ 
* approximately 99.7% of the curve area is between $\mu \pm 3\sigma$ 


## Simulating the Normal Distribution

In addition to calculating probabilities, we can simulate random normal values in R using `rnorm (s, mu, sigma)`.

_s_ = the number of random values we want to generate

$\mu$ = the mean of the distribution
    
$\sigma^2$ = the variance of the distribution

Default parameter settings in `rnorm()` are `mu=0` and `sigma=1`, so if we want a sample from the standard normal distribution, we only need to enter sample size, `rnorm(s)`.


# Assessing Normality

## Are data from a normal distribution?

Many statistical tests require data to be drawn from a normal distribution. Researchers may also interested in determining whether some variable of interest is normally distributed. For example, Belgian scholar [Adolphe Quetelet](http://www-groups.dcs.st-and.ac.uk/history/Biographies/Quetelet.html) (1796-1874) had a hypothesis that the natural distribution of human heights is a bell curve (i.e., normal distribution). 

We can investigate this using height data gathered by another famous statistician. [Francis Galton](http://www-history.mcs.st-andrews.ac.uk/Biographies/Galton.html) (1822-1911) investigated the relationship between the heights of parents and their offspring. Some of his data can be found in [galtonparentheights.csv](https://raw.githubusercontent.com/STAT-JET-ASU/Datasets/master/Instructor/galtonparentheights.csv).


## The Galton Height Data (Parents)

```{r, echo=FALSE, message=FALSE, warning=FALSE}
parent_hts <- read.csv("https://raw.githubusercontent.com/STAT-JET-ASU/Datasets/master/Instructor/galtonparentheights.csv")
```

```{r}
glimpse(parent_hts)
```

```{r}
ht_stats <- parent_hts %>% 
  summarize(xbar = mean(Father), s = sd(Father))
ht_stats
```


## Density Plot

Does the density of the data match a theoretical normal density plot with the same mean and variance?

```{r, eval=FALSE}
ggplot(parent_hts, aes(x = Father)) + 
  geom_density() +
  stat_function(fun = dnorm, 
                args = list(ht_stats$xbar, ht_stats$s),   
                color = "red")
```

Create a density plot of the data and superimpose a theoretical normal model on the same axes. Does the data deviate too far from the shape of the theoretical model?

Notice we are using `dnorm` because the density plot shows f(x).


## Data vs. Theoretical

```{r, echo=FALSE}
ggplot(parent_hts, aes(x = Father)) + 
  geom_density() +
  stat_function(fun = dnorm, 
                args = list(ht_stats$xbar, ht_stats$s), 
                color = "red")
```


## Empirical Cumulative Distribution Plot

Does the ECDF of the data match a theoretical normal CDF plot with the same mean and variance?

```{r, eval=FALSE}
ggplot(parent_hts, aes(x = Father)) + 
  stat_ecdf() +
  stat_function(fun = pnorm, 
                args = list(ht_stats$xbar, ht_stats$s), 
                color = "red")
```

Create an ECDF plot of the data and superimpose a theoretical normal model on the same axes. Does the data deviate too far from the shape of the theoretical model?

Notice we are using `pnorm` because the ECDF plot shows F(x).


## Data vs. Theoretical

```{r, echo=FALSE}
ggplot(parent_hts, aes(x = Father)) + 
  stat_ecdf() +
  stat_function(fun = pnorm, 
                args = list(ht_stats$xbar, ht_stats$s), 
                color = "red")
```


## Comparing Quantiles

Do data quantiles match the theoretical normal quantiles?

```{r}
deciles <- c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
tibble(data   = quantile(parent_hts$Father, deciles), 
       theory = round(qnorm(deciles, ht_stats$xbar, ht_stats$s),2))
```


## Plot of the Deciles

```{r, echo = FALSE}
plotdata <- tibble(data = quantile(parent_hts$Father, deciles), 
                   theory = qnorm(deciles, ht_stats$xbar, ht_stats$s))
ggplot(plotdata, aes(x = theory, y = data)) + 
  geom_point() + 
  geom_abline(slope = 1, intercept = 0, color = "red")
```


## Quantile-Quantile Plot (QQ Plot)

Do the quantiles of the data match the theoretical quantiles of a normal distribution with the same mean and variance?

```{r, eval=FALSE}
ggplot(parent_hts, aes(sample = Father)) + 
  stat_qq() +
  stat_qq_line(color = "red")
```

Notice the difference in syntax in the aesthetics, which uses `sample` rather than `x` to indicate the variable to be plotted. In the final plot, the x axis will be the theoretical quantiles on a standard normal curve, while the y axis is the data quantiles. There is a point representing each data value.


## QQ Plot

```{r, echo=FALSE}
ggplot(parent_hts, aes(sample = Father)) + 
  stat_qq() +
  stat_qq_line(color = "red")
```


## Skewness and Kurtosis

The skewness of a normal distribution is 0 and the kurtosis is 3. Data from a normal distribution should have similar values.

```{r}
library(moments)
skewK <- tibble(statistic = c("Skewness", "Kurtosis", "Excess K"),
                theory = c(0, 3, 0),
                data   = round(c(skewness(parent_hts$Father), 
                                 kurtosis(parent_hts$Father), 
                                 kurtosis(parent_hts$Father) - 3), 
                               2))
print.data.frame(skewK, row.names = FALSE)
```


## Galton Height Data

Assess the other Galton height measurements for normality. For the child data, perform the assessment with and without groups by gender. Was Quetelet right to think human height is normally distributed? How do you know?

* [galtonheightdata.csv](https://raw.githubusercontent.com/STAT-JET-ASU/Datasets/master/Instructor/galtonheightdata.csv) (for child data)

Additional human measurements can be found in the following datasets. Do they confirm or contradict Quetelet's hypotheses about height or other measurements? How do you know?

* [anthropometric.csv](https://raw.githubusercontent.com/STAT-JET-ASU/Datasets/master/Instructor/anthropometric.csv)
* [pearsonheightdata.csv](https://raw.githubusercontent.com/STAT-JET-ASU/Datasets/master/Instructor/pearsonheightdata.csv)


## Exploring Other Distributions

Construct a `tibble` containing samples of size 50 drawn from the following distributions. Assess normality for each sample. Repeat with samples of 1000.

<table>
<tr>
<td>
$X_1 \text{~} Unif(0,1)$<br>
$X_2 \text{~} Exp(1)$<br>
$X_3 \text{~} Bin(10, 0.5)$<br>
$X_4 \text{~} Bin(100, 0.5)$
</td>
<td>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;</td>
<td>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;</td>
<td>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;</td>
<td>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;</td>
<td>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;</td>
<td>
$X_5 \text{~} Bin(10, 0.2)$<br>
$X_6 \text{~} Bin(100, 0.2)$<br>
$X_8 \text{~} Bin(10, 0.8)$<br>
$X_9 \text{~} Bin(100, 0.8)$
</td>
<td>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;</td>
<td>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;</td>
<td>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;</td>
<td>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;</td>
<td>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;</td>
<td>
$X_{10} \text{~} t(3)$<br>
$X_{11} \text{~} t(20)$<br>
$X_{12} \text{~} t(100)$<br>
$X_{13} \text{~} t(250)$
</td>
</tr>
</table><p>

For each distribution, consider the shape of its pmf or pdf and CDF versus those of the normal distribution. 

Look at the shapes that tend to be produced by skewed data, data that is flatter than a bell curve (e.g., uniform), or discrete data (e.g., binomial), as well as skewness and kurtosis.

